# syntax=docker/dockerfile:1.2
ARG BASE_IMAGE
ARG PYTHON_VERSION

FROM $BASE_IMAGE

# prevents public key not available error for Nvidia images (https://github.com/NVIDIA/nvidia-docker/issues/1632)
RUN rm -rf /etc/apt/sources.list.d/cuda.list && rm -rf /etc/apt/sources.list.d/nvidia-ml.list
RUN apt-get update && \
    apt-get -y install --no-install-recommends \
      build-essential  \
      ca-certificates  \
      g++  \
      make  \
      cmake  \
      unzip  \
      libcurl4-openssl-dev  \
      wget \
      git \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Download and install Anaconda.
ARG ANACONDA_VERSION="py39_4.10.3"
ARG PYTHON_VERSION
RUN UNAME_M="$(uname -m)" \
    && if [ "${UNAME_M}" = "x86_64" ]; then  \
        MINICONDA_URL="https://repo.anaconda.com/miniconda/Miniconda3-${ANACONDA_VERSION}-Linux-x86_64.sh";\
       elif [ "${UNAME_M}" = "aarch64" ]; then \
        MINICONDA_URL="https://repo.anaconda.com/miniconda/Miniconda3-${ANACONDA_VERSION}-Linux-aarch64.sh";\
    fi && wget -O /tmp/anaconda.sh "${MINICONDA_URL}" &&  \
    chmod +x /tmp/anaconda.sh && \
    mkdir /root/.conda && \
    bash -c "/tmp/anaconda.sh -b -p /opt/conda" && \
    rm /tmp/anaconda.sh && \
    /opt/conda/bin/conda create -n env python=${PYTHON_VERSION} && \
    /opt/conda/bin/conda clean -ya && \
    echo ". /opt/conda/etc/profile.d/conda.sh" >> ~/.bashrc && \
    echo "conda activate env" >> ~/.bashrc
SHELL ["/opt/conda/bin/conda", "run", "--no-capture-output", "-n", "env", "/bin/bash", "-c"]

# Create directories for code and model weights
RUN mkdir -p /home/model-server && mkdir -p /opt/ml/model
WORKDIR /home/model-server

# Install requirements
RUN pip install --no-cache-dir -U pip awscli~=1.18.195
COPY requirements_seldon.txt /home/model-server/.requirements/base_requirements.txt
ARG AWS_DEFAULT_REGION=us-east-1
ARG PIP_REPO
RUN --mount=type=secret,id=aws,target=/root/.aws/credentials,required=true,uid=1000,gid=1000 \
    --mount=type=cache,target=/root/.cache/pip \
    aws codeartifact login --tool pip --domain superai --repository ${PIP_REPO} && \
    pip install --no-cache-dir -r /home/model-server/.requirements/base_requirements.txt
    
# Install superai version from local path/repository
COPY .dist/*.whl /home/model-server/.requirements/
ARG SUPERAI_WHL
RUN --mount=type=secret,id=aws,target=/root/.aws/credentials,required=true \
    --mount=type=cache,target=/root/.cache/pip \
    aws codeartifact login --tool pip --domain superai --repository ${PIP_REPO} && \
    pip install --no-cache-dir '/home/model-server/.requirements/${SUPERAI_WHL}[ai]'

LABEL io.openshift.s2i.scripts-url="image:///s2i/bin"

COPY s2i/bin /s2i/bin
COPY s2i/bin /opt/program

ENV PATH="/opt/program:${PATH}"

RUN chmod a+rwx /opt/program && \
    mkdir -p /.conda && \
    chmod a+rwx /.conda

EXPOSE 5000
WORKDIR /opt/program
